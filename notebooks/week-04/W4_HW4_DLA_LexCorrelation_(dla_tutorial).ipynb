{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CompPsychology/psych290_colab_public/blob/main/notebooks/week-04/W4_HW4_DLA_LexCorrelation_(dla_tutorial).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc73adb",
      "metadata": {
        "id": "fdc73adb"
      },
      "source": [
        "# W4 Homework 4: Weighted dictionaries and correlations\n",
        "\n",
        "(c) Johannes Eichstaedt & the World Well-Being Project, 2023.\n",
        "\n",
        "‚úãüèª‚úãüèª NOTE - You need to create a copy of this notebook before you work through it. Click on \"Save a copy in Drive\" option in the File menu, and safe it to your Google Drive.\n",
        "\n",
        "‚úâÔ∏èüêû If you find a bug/something doesn't work, please slack us a screenshot, or email johannes.courses@gmail.com."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c685534",
      "metadata": {
        "id": "9c685534"
      },
      "source": [
        "Before you start solving the question, set up the as usual, to execute sql and dlatk commands in the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Setting up Colab with DLATK and SQLite"
      ],
      "metadata": {
        "id": "jnfycVJzLgdm"
      },
      "id": "jnfycVJzLgdm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) Install DLATK\n"
      ],
      "metadata": {
        "id": "nB4PBdgJLlet"
      },
      "id": "nB4PBdgJLlet"
    },
    {
      "cell_type": "code",
      "source": [
        "# assigning the database name\n",
        "database = \"dla_tutorial\""
      ],
      "metadata": {
        "id": "sMF0apTdLzxD"
      },
      "id": "sMF0apTdLzxD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing DLATK and necessary packages\n",
        "!git clone -b psych290 https://github.com/dlatk/dlatk.git\n",
        "!pip install -r dlatk/install/requirements.txt\n",
        "!pip install dlatk/\n",
        "!pip install wordcloud langid jupysql"
      ],
      "metadata": {
        "id": "Xq-bBNjEL2Ni",
        "outputId": "d7e3a43f-a5c7-4c1b-8170-6c402cd7f582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Xq-bBNjEL2Ni",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dlatk'...\n",
            "remote: Enumerating objects: 6991, done.\u001b[K\n",
            "remote: Counting objects: 100% (1076/1076), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 6991 (delta 994), reused 935 (delta 927), pack-reused 5915 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6991/6991), 62.38 MiB | 7.99 MiB/s, done.\n",
            "Resolving deltas: 100% (4947/4947), done.\n",
            "Updating files: 100% (338/338), done.\n",
            "Collecting image<=1.5.33 (from -r dlatk/install/requirements.txt (line 1))\n",
            "  Downloading image-1.5.33.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langid<=1.1.6,>=1.1.4 (from -r dlatk/install/requirements.txt (line 2))\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib<=3.10.0,>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 3)) (3.10.0)\n",
            "Collecting mysqlclient<=2.1.1 (from -r dlatk/install/requirements.txt (line 4))\n",
            "  Downloading mysqlclient-2.1.1.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk<=3.9.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 5)) (3.9.1)\n",
            "Requirement already satisfied: numpy<=2.0.2 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: pandas<=2.2.2,>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: patsy<=1.0.1,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<=2.8.2,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: rpy2<=3.5.17 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 10)) (3.5.17)\n",
            "Requirement already satisfied: scikit-learn<=1.6.1 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 11)) (1.6.1)\n",
            "Requirement already satisfied: scipy<=1.14.1,>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 12)) (1.14.1)\n",
            "Collecting SQLAlchemy<=2.0.39,>=0.9.9 (from -r dlatk/install/requirements.txt (line 13))\n",
            "  Downloading sqlalchemy-2.0.39-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: statsmodels<=0.14.4,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 14)) (0.14.4)\n",
            "Requirement already satisfied: wordcloud<=1.9.4,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from -r dlatk/install/requirements.txt (line 15)) (1.9.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from image<=1.5.33->-r dlatk/install/requirements.txt (line 1)) (11.1.0)\n",
            "Collecting django (from image<=1.5.33->-r dlatk/install/requirements.txt (line 1))\n",
            "  Downloading Django-5.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from image<=1.5.33->-r dlatk/install/requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10.0,>=1.3.1->-r dlatk/install/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10.0,>=1.3.1->-r dlatk/install/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10.0,>=1.3.1->-r dlatk/install/requirements.txt (line 3)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10.0,>=1.3.1->-r dlatk/install/requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10.0,>=1.3.1->-r dlatk/install/requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10.0,>=1.3.1->-r dlatk/install/requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<=3.9.1,>=3.1->-r dlatk/install/requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<=3.9.1,>=3.1->-r dlatk/install/requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<=3.9.1,>=3.1->-r dlatk/install/requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<=3.9.1,>=3.1->-r dlatk/install/requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<=2.2.2,>=0.17.1->-r dlatk/install/requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<=2.2.2,>=0.17.1->-r dlatk/install/requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: cffi>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from rpy2<=3.5.17->-r dlatk/install/requirements.txt (line 10)) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from rpy2<=3.5.17->-r dlatk/install/requirements.txt (line 10)) (3.1.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2<=3.5.17->-r dlatk/install/requirements.txt (line 10)) (5.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<=1.6.1->-r dlatk/install/requirements.txt (line 11)) (3.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<=2.0.39,>=0.9.9->-r dlatk/install/requirements.txt (line 13)) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<=2.0.39,>=0.9.9->-r dlatk/install/requirements.txt (line 13)) (4.13.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.15.1->rpy2<=3.5.17->-r dlatk/install/requirements.txt (line 10)) (2.22)\n",
            "Collecting asgiref>=3.8.1 (from django->image<=1.5.33->-r dlatk/install/requirements.txt (line 1))\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from django->image<=1.5.33->-r dlatk/install/requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->rpy2<=3.5.17->-r dlatk/install/requirements.txt (line 10)) (3.0.2)\n",
            "Downloading sqlalchemy-2.0.39-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Django-5.2-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: image, langid, mysqlclient\n",
            "  Building wheel for image (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image: filename=image-1.5.33-py2.py3-none-any.whl size=19482 sha256=1bc8e9df1bb5a14e5d62ffe7ee2c6e127797fd20f5f0dd11718507add1d51905\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/40/4f/3c9a8d0f22a1a6f966975a460e5cb509a1e7dc42e2ce5d9a6d\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=b7a673d0f24970710f3271b9a8afe6b96f7ae50d46079e60bf8dbbd2b58a82a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/6a/b6/b7eb43a6ad55b139c15c5daa29f3707659cfa6944d3c696f5b\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.1-cp311-cp311-linux_x86_64.whl size=106437 sha256=9275c6d42e626d6e89c61c0bbb6cdeec8ecf4e34a89bdf0194625466b190b892\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/44/b2/cdf313664c12c8b11f88afd90079823c63369ab9135fc79185\n",
            "Successfully built image langid mysqlclient\n",
            "Installing collected packages: SQLAlchemy, mysqlclient, langid, asgiref, django, image\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.40\n",
            "    Uninstalling SQLAlchemy-2.0.40:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.40\n",
            "Successfully installed SQLAlchemy-2.0.39 asgiref-3.8.1 django-5.2 image-1.5.33 langid-1.1.6 mysqlclient-2.1.1\n",
            "Processing ./dlatk\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk<=3.9.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from dlatk==1.3.1) (3.9.1)\n",
            "Requirement already satisfied: numpy<=2.0.2 in /usr/local/lib/python3.11/dist-packages (from dlatk==1.3.1) (2.0.2)\n",
            "Requirement already satisfied: pandas<=2.2.2,>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from dlatk==1.3.1) (2.2.2)\n",
            "Requirement already satisfied: patsy<=1.0.1,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from dlatk==1.3.1) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<=2.8.2,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from dlatk==1.3.1) (2.8.2)\n",
            "Requirement already satisfied: scikit-learn<=1.6.1 in /usr/local/lib/python3.11/dist-packages (from dlatk==1.3.1) (1.6.1)\n",
            "Requirement already satisfied: scipy<=1.14.1,>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from dlatk==1.3.1) (1.14.1)\n",
            "Requirement already satisfied: statsmodels<=0.14.4,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from dlatk==1.3.1) (0.14.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<=3.9.1,>=3.1->dlatk==1.3.1) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<=3.9.1,>=3.1->dlatk==1.3.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<=3.9.1,>=3.1->dlatk==1.3.1) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<=3.9.1,>=3.1->dlatk==1.3.1) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<=2.2.2,>=0.17.1->dlatk==1.3.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<=2.2.2,>=0.17.1->dlatk==1.3.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<=2.8.2,>=2.5.0->dlatk==1.3.1) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<=1.6.1->dlatk==1.3.1) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels<=0.14.4,>=0.5.0->dlatk==1.3.1) (24.2)\n",
            "Building wheels for collected packages: dlatk\n",
            "  Building wheel for dlatk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dlatk: filename=dlatk-1.3.1-py3-none-any.whl size=35635918 sha256=357ec3d13d80e8fdd16fb77d3bffac1d867b7619d88e25b9d0b8299ee135d211\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a2kox69l/wheels/cc/c9/65/e1ecc64bac68518c07b286fe86921aa938e11a0c3a87d8ff93\n",
            "Successfully built dlatk\n",
            "Installing collected packages: dlatk\n",
            "Successfully installed dlatk-1.3.1\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: langid in /usr/local/lib/python3.11/dist-packages (1.1.6)\n",
            "Collecting jupysql\n",
            "  Downloading jupysql-0.11.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from wordcloud) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from wordcloud) (3.10.0)\n",
            "Requirement already satisfied: prettytable>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from jupysql) (3.16.0)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (from jupysql) (2.0.39)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.11/dist-packages (from jupysql) (0.5.3)\n",
            "Requirement already satisfied: ipython-genutils>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from jupysql) (0.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from jupysql) (3.1.6)\n",
            "Requirement already satisfied: sqlglot>=11.3.7 in /usr/local/lib/python3.11/dist-packages (from jupysql) (25.20.2)\n",
            "Collecting jupysql-plugin>=0.4.2 (from jupysql)\n",
            "  Downloading jupysql_plugin-0.4.5-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting ploomber-core>=0.2.7 (from jupysql)\n",
            "  Downloading ploomber_core-0.2.26-py3-none-any.whl.metadata (527 bytes)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ploomber-core>=0.2.7->jupysql) (6.0.2)\n",
            "Collecting posthog (from ploomber-core>=0.2.7->jupysql)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable>=3.12.0->jupysql) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->jupysql) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->jupysql) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->jupysql) (4.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from posthog->ploomber-core>=0.2.7->jupysql) (2.32.3)\n",
            "Collecting monotonic>=1.5 (from posthog->ploomber-core>=0.2.7->jupysql)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->ploomber-core>=0.2.7->jupysql)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog->ploomber-core>=0.2.7->jupysql) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.7->jupysql) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.7->jupysql) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.7->jupysql) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.7->jupysql) (2025.1.31)\n",
            "Downloading jupysql-0.11.1-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupysql_plugin-0.4.5-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m192.8/192.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ploomber_core-0.2.26-py3-none-any.whl (22 kB)\n",
            "Downloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Installing collected packages: monotonic, backoff, posthog, ploomber-core, jupysql-plugin, jupysql\n",
            "Successfully installed backoff-2.2.1 jupysql-0.11.1 jupysql-plugin-0.4.5 monotonic-1.6 ploomber-core-0.2.26 posthog-3.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Mount Google Drive and copy database"
      ],
      "metadata": {
        "id": "imR4jwbgL3sE"
      },
      "id": "imR4jwbgL3sE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive & copy database to Colab\n",
        "\n",
        "# connects & mounts your Google Drive to this colab space\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# copies {database_name}.db to the sqlite_data folder in this Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/{database}.db\" \"sqlite_data\"\n",
        "\n",
        "# this copies dlatk_lexica.db from your Google Drive to Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/dlatk_lexica.db\" \"sqlite_data\""
      ],
      "metadata": {
        "id": "dIpmCWo0L98n",
        "outputId": "dc0b5582-ea04-499c-fb33-65db0719bace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dIpmCWo0L98n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) Setup database connection"
      ],
      "metadata": {
        "id": "KwUvoGWCMAfd"
      },
      "id": "KwUvoGWCMAfd"
    },
    {
      "cell_type": "code",
      "source": [
        "# loads the %%sql extension\n",
        "%load_ext sql\n",
        "\n",
        "# connects the extension to the database\n",
        "from sqlalchemy import create_engine\n",
        "tutorial_db_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "dlatk_lexica_engine = create_engine(f\"sqlite:///sqlite_data/dlatk_lexica.db?charset=utf8mb4\")\n",
        "\n",
        "# attaches the dlatk_lexica.db so tutorial_db_engine can query both databases\n",
        "from IPython import get_ipython\n",
        "from sqlalchemy import event\n",
        "\n",
        "# auto‚Äëattach the lexica db whenever tutorial_db_engine connects\n",
        "@event.listens_for(tutorial_db_engine, \"connect\")\n",
        "def _attach_lexica(dbapi_conn, connection_record):\n",
        "    dbapi_conn.execute(\"ATTACH DATABASE 'sqlite_data/dlatk_lexica.db' AS dlatk_lexica;\")\n",
        "\n",
        "%sql tutorial_db_engine\n",
        "\n",
        "#set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50"
      ],
      "metadata": {
        "id": "X3tCYlBEMCKM"
      },
      "id": "X3tCYlBEMCKM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d) (ONLY IF NEEDED: SOFT RELOAD): **If you have a \"database lock\" problem**"
      ],
      "metadata": {
        "id": "XRMuk5ToMDhT"
      },
      "id": "XRMuk5ToMDhT"
    },
    {
      "cell_type": "code",
      "source": [
        "# If you face a \"database locked\" issue, restart the session & run this cell to get set back up!\n",
        "\n",
        "database = \"dla_tutorial\"\n",
        "\n",
        "%reload_ext sql\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "tutorial_db_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "dlatk_lexica_engine = create_engine(f\"sqlite:///sqlite_data/dlatk_lexica.db?charset=utf8mb4\")\n",
        "\n",
        "# set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50\n",
        "\n",
        "from IPython import get_ipython\n",
        "from sqlalchemy import event\n",
        "\n",
        "# auto‚Äëattach the lexica db whenever tutorial_db_engine connects\n",
        "@event.listens_for(tutorial_db_engine, \"connect\")\n",
        "def _attach_lexica(dbapi_conn, connection_record):\n",
        "    dbapi_conn.execute(\"ATTACH DATABASE 'sqlite_data/dlatk_lexica.db' AS dlatk_lexica;\")\n",
        "\n",
        "%sql tutorial_db_engine"
      ],
      "metadata": {
        "id": "DVW0KVbRMFi7"
      },
      "id": "DVW0KVbRMFi7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1665f621",
      "metadata": {
        "id": "1665f621"
      },
      "source": [
        "# ü¶Üüë©‚ÄçüöÄ Questions\n",
        "\n",
        "**FOR ALL QUESTIONS:  \n",
        "Please remember to summarize your answers in one sentence using human language.**\n",
        "\n",
        "‚ö†Ô∏è TIP: for all of our sanity, please remember that you can pipe away DLATK output with `>bla.txt 2>&1` at the end of the command.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Please correlate *LIWC* (`POSEMO`), _labmt_ (`valence`) and *NRC* (`SENT`) against `gender`, and report the correlations (with CIs and p-values). For which one do you see the highest correlation?\n",
        "\n",
        "**FYI:** Feel free to use `mini_LIWC2015` to extract `POSEMO` features."
      ],
      "metadata": {
        "id": "QwypLzFDMPK9"
      },
      "id": "QwypLzFDMPK9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**"
      ],
      "metadata": {
        "id": "bNQmMSw9AoCG"
      },
      "id": "bNQmMSw9AoCG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8mT-a5koAvBv"
      },
      "id": "8mT-a5koAvBv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fd758740",
      "metadata": {
        "id": "fd758740"
      },
      "source": [
        "## 2) What's the correlation for the (mini or full) LIWC `POSEMO` category with gender controlling for age, with confidence intervals? Is it significant?  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b35f67e",
      "metadata": {
        "id": "0b35f67e"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMgdLzNIAuxL"
      },
      "id": "lMgdLzNIAuxL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3)"
      ],
      "metadata": {
        "id": "U0Sj_ZfLOMA-"
      },
      "id": "U0Sj_ZfLOMA-"
    },
    {
      "cell_type": "markdown",
      "id": "07eab1c1",
      "metadata": {
        "id": "07eab1c1"
      },
      "source": [
        "### 3a) Please extract the data-driven machine-learning based age and gender dictionaries from an [EMNLP'14](https://www.aclweb.org/anthology/D14-1121.pdf) paper.\n",
        "\n",
        "It's in `dlatk_lexica.dd_emnlp15_ageGender`. Please correlate its dictionaries against the age and gender variables. How well are the age and gender of blog authors predicted by it? Is its gender dictionary's correlation with gender higher than that of the sentiment dictionaries' correlation with gender determined in question 2 above?\n",
        "\n",
        "**Note:** Both for the Gender dictionary and in our outcomes, gender = 1 means **woman**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81a0195",
      "metadata": {
        "id": "e81a0195"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UyL_vaYNAxRF"
      },
      "id": "UyL_vaYNAxRF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1e7e65a0",
      "metadata": {
        "id": "1e7e65a0"
      },
      "source": [
        "### 3b) Find the 5 messages that are scored to be \"the oldest\" (using the `--top_messages` flag).\n",
        "\n",
        "Please restrict to messages with at least 20 tokens (for the messages to make sense).\n",
        "\n",
        "**Hint:** Use `--group_freq_thresh`.\n",
        "\n",
        "**Note:** May take a while!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c3e9698",
      "metadata": {
        "id": "6c3e9698"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNM_m_FEAz7v"
      },
      "id": "YNM_m_FEAz7v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f453fe77",
      "metadata": {
        "id": "f453fe77"
      },
      "source": [
        "## 4) Please extract and correlate all of the LIWC 2015 categories against one-hot encoded occupation controlling for gender. What LIWC category is most correlated with working in `BIOTECH`? Or put differently, which LIWC category is most distinguishing of authors working in `BIOTECH`?\n",
        "\n",
        "**Note:** you will get A LOT of console DLATK output. Please pipe it away by adding `> bla.txt 2>&1` (or any filename) to your command, like we did in the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc717690",
      "metadata": {
        "id": "bc717690"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaV8iB90A8y0"
      },
      "id": "AaV8iB90A8y0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8d51503f",
      "metadata": {
        "id": "8d51503f"
      },
      "source": [
        "## 5) In the above results, can you write 1-2 sentences stating and minimally interpreting  the associations for student authors, drawing on [Tausczik & Pennebaker](https://drive.google.com/file/d/1iAB7trS4puQUjBJVQBxk7cHUm4NA5PoR/view?usp=sharing)--the appendix is a good place to look.\n",
        "\n",
        "For example, \"Across N = NNN authors, we observed that X-occupation is correlated with Y-languageCategory at r = Z \\[CI, CI\\], p = ZZZ when controlling for gender. This suggests that people in X-occupation may use more YY language, which has been previously associated with increased ZZ-PsychologicalConstruct (someCitation).\"\n",
        "\n",
        "Feel free to write something smoother, but don't write a lot.\n",
        "\n",
        "**Please do the LIWC readings! A friendly shout out.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b51c0e1",
      "metadata": {
        "scrolled": false,
        "id": "8b51c0e1"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d84bcc",
      "metadata": {
        "id": "b3d84bcc"
      },
      "source": [
        "## 6) Correlate the meta features against age, controlling for gender. What do you observe? Can you interpret the word length finding (minimally) drawing on T&P, as above?\n",
        "\n",
        "**Note:** The meta feature table has a similar structure as a regular feature table. You can simply pass it to DLATK with `--feat_table`, and it will do as you say.\n",
        "\n",
        "(**Note:** LIWC implements word length as fraction of words with more than 6 characters, DLATK uses token length. Same idea / you can use the same references)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65571425",
      "metadata": {
        "id": "65571425"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pehTBPS_BANQ"
      },
      "id": "pehTBPS_BANQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cd2d5b73",
      "metadata": {
        "id": "cd2d5b73"
      },
      "source": [
        "## 7) If you set the group frequency threshold to 2,000 to run the LIWC POSEMO correlation against gender, does the result change from question 1? How many users is the correlation now run over?\n",
        "\n",
        "**Tip:** look at the DLATK console output to get to that info quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518700a0",
      "metadata": {
        "id": "518700a0"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJV1u_ThBB-i"
      },
      "id": "QJV1u_ThBB-i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "56cdf978",
      "metadata": {
        "id": "56cdf978"
      },
      "source": [
        "## 8) For question 7, how could you check that the number of users with 2000 words is correct in SQL using the meta_1gram_user table?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b13376b",
      "metadata": {
        "id": "7b13376b"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AU9xZQltBC0V"
      },
      "id": "AU9xZQltBC0V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d60a7033",
      "metadata": {
        "id": "d60a7033"
      },
      "source": [
        "## 9) (2 pts) Please find the LIWC2015 dictionary that correlates most strongly with younger age, when controlling for gender.\n",
        "\n",
        "* Once you have found which dictionary this is, see how the top 10 most frequent words are associated with younger age (so negatively associated, controlling for gender), and produce a table that could go into the supplement of your paper. It should contain the total frequency of the words (in descending order), their beta coefficients, with 95% Confidence Intervals.\n",
        "\n",
        "* Ty to make it look not terrible -- we recommend you use the **excel template** for formatting that we have provided with the tutorial in your home folder, it'll make it nice looking. But we know you are busy/may hate excel for some reason, etc.\n",
        "\n",
        "You can add an image to Colab from your machine by being in a markdown cell, then clicking the Insert Image icon, and then executing that cell. Colab will now render your image and save it!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d457d7e3",
      "metadata": {
        "id": "d457d7e3"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-uaFhZmBEop"
      },
      "id": "Q-uaFhZmBEop",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save your database and output!**"
      ],
      "metadata": {
        "id": "aoQ-eB0_Sucd"
      },
      "id": "aoQ-eB0_Sucd"
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'dla_tutorial'"
      ],
      "metadata": {
        "id": "iTJZCqcfSxUq"
      },
      "id": "iTJZCqcfSxUq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# copy the database file to your Drive\n",
        "!cp -f \"sqlite_data/{database}.db\" \"/content/drive/MyDrive/sqlite_databases/\"\n",
        "\n",
        "print(f\"‚úÖ Database '{database}.db' has been copied to your Google Drive.\")"
      ],
      "metadata": {
        "id": "zjmFtQXqSzuS"
      },
      "id": "zjmFtQXqSzuS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, save your data!"
      ],
      "metadata": {
        "id": "LTKxtVgDS1C6"
      },
      "id": "LTKxtVgDS1C6"
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = './outputs_hw4'"
      ],
      "metadata": {
        "id": "u0aMIrXrS43W"
      },
      "id": "u0aMIrXrS43W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Copy the database file to your Drive (-r makes it copy the folder and all files/folders inside)\n",
        "!cp -f -r {OUTPUT_FOLDER} \"/content/drive/MyDrive/\"\n",
        "\n",
        "print(f\"‚úÖ '{OUTPUT_FOLDER}' has been copied to your Google Drive.\")"
      ],
      "metadata": {
        "id": "-SmsT-ROS5S6"
      },
      "id": "-SmsT-ROS5S6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}