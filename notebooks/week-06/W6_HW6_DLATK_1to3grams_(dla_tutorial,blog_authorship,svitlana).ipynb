{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CompPsychology/psych290_colab_public/blob/main/notebooks/week-06/W6_HW6_DLATK_1to3grams_(dla_tutorial%2Cblog_authorship%2Csvitlana).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8894fd43",
      "metadata": {
        "id": "8894fd43"
      },
      "source": [
        "# W6 Homework 6: Tuning 1to3grams, extraction & correlation (DB: dla_tutorial, blog_authorship, svitlana)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37402d54",
      "metadata": {
        "id": "37402d54"
      },
      "source": [
        "(c) Johannes Eichstaedt & the World Well-Being Project, 2023.\n",
        "\n",
        "✋🏻✋🏻 NOTE - You need to create a copy of this notebook before you work through it. Click on \"Save a copy in Drive\" option in the File menu, and safe it to your Google Drive.\n",
        "\n",
        "✉️🐞 If you find a bug/something doesn't work, please slack us a screenshot, or email johannes.courses@gmail.com.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This homework will work with 3 different datasets.\n",
        "\n",
        "* Questions 1-2: `dla_tutorial` (from your Google Drive)\n",
        "* Questions 3-4: `blog_authorship` (./psych290/blog_authorship/*.csv in your file tree)\n",
        "* Question 5: `svitlana` (./psych290/svitlana/*.csv in your file tree)\n",
        "\n",
        "😎 We'll walk you through the database setup for each!"
      ],
      "metadata": {
        "id": "QHtO0tlh_umD"
      },
      "id": "QHtO0tlh_umD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "☝🏻💡 Quick tip: in this homework, many of the DLATK commands can take a while to run (1-2 hours). So if you're working on the HW over a few days make sure to **save your database file to Google Drive frequently**! (See bottom of the notebook for code cells to save each database)."
      ],
      "metadata": {
        "id": "OqNQ7YmYNPot"
      },
      "id": "OqNQ7YmYNPot"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please set up Colab first, as usual!"
      ],
      "metadata": {
        "id": "l8O_jHcJA9S9"
      },
      "id": "l8O_jHcJA9S9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup DLATK"
      ],
      "metadata": {
        "id": "Lj20EyPlMOEj"
      },
      "id": "Lj20EyPlMOEj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install DLATK"
      ],
      "metadata": {
        "id": "vXIZXCgbTq1i"
      },
      "id": "vXIZXCgbTq1i"
    },
    {
      "cell_type": "code",
      "source": [
        "# installing DLATK and necessary packages\n",
        "!git clone -b psych290 https://github.com/dlatk/dlatk.git\n",
        "!pip install -r dlatk/install/requirements.txt\n",
        "!pip install dlatk/\n",
        "!pip install wordcloud langid jupysql"
      ],
      "metadata": {
        "id": "AMAiPZ6wTsvf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "AMAiPZ6wTsvf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the data for this tutorial"
      ],
      "metadata": {
        "id": "1LENmEIGagjL"
      },
      "id": "1LENmEIGagjL"
    },
    {
      "cell_type": "code",
      "source": [
        "# this downloads the csvs we need for this tutorial\n",
        "!git clone https://github.com/CompPsychology/psych290_data.git"
      ],
      "metadata": {
        "id": "1XDC_86m9BP0"
      },
      "id": "1XDC_86m9BP0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a look on the left in the file browser, you see csv files in ./psych290_data/blog_authorship and in ./psych290_data/svitlana"
      ],
      "metadata": {
        "id": "V1Jld6HA9Ia6"
      },
      "id": "V1Jld6HA9Ia6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive and copy databases"
      ],
      "metadata": {
        "id": "ODME1wvF9Tj6"
      },
      "id": "ODME1wvF9Tj6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you don't have that `dlatk_lexica.db` in your Google Drive, look at Tutorial 5."
      ],
      "metadata": {
        "id": "FQ2EUuD09Xv7"
      },
      "id": "FQ2EUuD09Xv7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive & copy to Colab\n",
        "\n",
        "# connects & mounts your Google Drive to this colab space\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# this copies dla_tutorial.db from your Google Drive to Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/dla_tutorial.db\" \"sqlite_data\"\n",
        "\n",
        "# this copies dlatk_lexica.db from your Google Drive to Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/dlatk_lexica.db\" \"sqlite_data\""
      ],
      "metadata": {
        "id": "gfQjrHy1MRXT"
      },
      "id": "gfQjrHy1MRXT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BTW: we have 3 different databases we'll be working within this homework 😎"
      ],
      "metadata": {
        "id": "TljJBDz3AVsU"
      },
      "id": "TljJBDz3AVsU"
    },
    {
      "cell_type": "markdown",
      "id": "1a83affa",
      "metadata": {
        "id": "1a83affa"
      },
      "source": [
        "## 1) (2 pts) How many 2 grams are there...\n",
        "\n",
        "...in the `dla_tutorial` dataset (the `msgs` and `outcomes` tables in your dla_tutorial.db.) that meet a Pointwise Mutual Information criterion of `PMI > 5`, and that meet an occurrence threshold of being present in `7%` of the groups that meet a group_freq_threshold of `500`? What are the most frequent 10 of these 2grams by average group_norm across users?\n",
        "\n",
        "First things first, let's connect to the `dla_tutorial` SQLite database!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'dla_tutorial'\n",
        "\n",
        "# loads the %%sql extension\n",
        "%load_ext sql\n",
        "\n",
        "# connects the extension to the database - mounts the database as an engine\n",
        "from sqlalchemy import create_engine\n",
        "dla_tutorial_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "\n",
        "# use tutorial_db_engine engine\n",
        "%sql dla_tutorial_engine\n",
        "\n",
        "#set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50"
      ],
      "metadata": {
        "id": "fUzrfByi_w3A"
      },
      "id": "fUzrfByi_w3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pro-tip:** Ingest the unfiltered 2gram feature table, and filter it down."
      ],
      "metadata": {
        "id": "4Z_yjhhf_wb2"
      },
      "id": "4Z_yjhhf_wb2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**"
      ],
      "metadata": {
        "id": "K0KLRVq9-mOa"
      },
      "id": "K0KLRVq9-mOa"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pgeAgvtZ-nma"
      },
      "id": "pgeAgvtZ-nma",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8100b289",
      "metadata": {
        "id": "8100b289"
      },
      "source": [
        "## 2) Make word clouds for the correlated 2grams for different occupations (one-hot encoded) with a occurrence threshold of being present in 10% of the groups that have at least 500 tokens and a PMI of 4.\n",
        "\n",
        "Look at the word clouds -- what's the bi-gram most associated with student status?\n",
        "\n",
        "**Pro-tip:** Pipe away the DLATK output (especially while producing wordclouds)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "906e3684",
      "metadata": {
        "id": "906e3684"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7VC-ZuKj-q1v"
      },
      "id": "7VC-ZuKj-q1v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d3a2c7f4",
      "metadata": {
        "id": "d3a2c7f4"
      },
      "source": [
        "## 3) (3 pt) Full blog-authorship dataset: descriptives\n",
        "\n",
        "You will now switch databases to a new `blog_authorship` database. It contains a larger corpus of blogs! Have a look around in that database to get yourself oriented.\n",
        "\n",
        "<!-- Please don't extract 1, 2 or 3 grams in this corpus, that would take 8.5 hours -- per person in the class. Instead, we have extracted feature tables using the usual DLATK commands for you. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup the SQLite database file from CSVs"
      ],
      "metadata": {
        "id": "sUH-wfxDKQ4X"
      },
      "id": "sUH-wfxDKQ4X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First things first, we need to create the new database from the CSV files we cloned (downloaded) from the `psych290_data` GitHub repository."
      ],
      "metadata": {
        "id": "7U6czw2GKtJH"
      },
      "id": "7U6czw2GKtJH"
    },
    {
      "cell_type": "code",
      "source": [
        "# define the new database name\n",
        "database='blog_authorship'"
      ],
      "metadata": {
        "id": "NAOxlKRueNal"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NAOxlKRueNal"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dlatk.tools.importmethods import csvToSQLite\n",
        "\n",
        "# point to the database file path\n",
        "database_path = os.path.join(\"sqlite_data\", database)\n",
        "\n",
        "# insert the messages CSV into the new database\n",
        "csvToSQLite(\"./psych290_data/blog_authorship/blog_authorship_msgs_2k.csv\", database_path, \"blog_authorship_msgs\")\n",
        "\n",
        "# insert the outcomes CSV into the new database\n",
        "csvToSQLite(\"./psych290_data/blog_authorship/blog_authorship_outcomes_2k.csv\", database_path, \"blog_authorship_outcomes\")"
      ],
      "metadata": {
        "id": "8wjtnZAieNal"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8wjtnZAieNal"
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡 If you're returning to this homework (e.g., you already extracted 1to3grams and saved the database to Google Drive) and do not want to recreate your blog_authorship database, you can:\n",
        "* (1) Mount your Google Drive\n",
        "* (2) copy over your existing blog_authorship.db file.\n",
        "\n",
        "```\n",
        "# Mount Google Drive & copy to Colab\n",
        "\n",
        "# connects & mounts your Google Drive to this colab space\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# this copies blog_authorship.db from your Google Drive to Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/blog_authorship.db\" \"sqlite_data\"\n",
        "```"
      ],
      "metadata": {
        "id": "ztN4Gy74MACk"
      },
      "id": "ztN4Gy74MACk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the usual SQLite database connection procedure!"
      ],
      "metadata": {
        "id": "fMbZoWJqMYtV"
      },
      "id": "fMbZoWJqMYtV"
    },
    {
      "cell_type": "code",
      "source": [
        "# reloads the %%sql extension\n",
        "%reload_ext sql\n",
        "\n",
        "# connects the extension to the database - mounts the database as an engine\n",
        "from sqlalchemy import create_engine\n",
        "blog_authorship_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "\n",
        "# use engine (this activates the connection!)\n",
        "%sql blog_authorship_engine\n",
        "\n",
        "#set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50"
      ],
      "metadata": {
        "id": "raV0o1LOej8e"
      },
      "id": "raV0o1LOej8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extract 1to3gram features"
      ],
      "metadata": {
        "id": "EZT_d5dNM7AR"
      },
      "id": "EZT_d5dNM7AR"
    },
    {
      "cell_type": "markdown",
      "id": "fd697c9f",
      "metadata": {
        "id": "fd697c9f"
      },
      "source": [
        "Here's the command to extract 1to3 grams with good, high-quality settings for this dataset that err on the side of including more features for discovery: Occurrence threshold = 5%, Pointwise-mutual information PMI = 3. Group-frquency threshold GFT of 1000.\n",
        "\n",
        "**This will take ~70 minutes!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'blog_authorship'\n",
        "msgs_table = 'blog_authorship_msgs'"
      ],
      "metadata": {
        "id": "sttENThcfAj_"
      },
      "id": "sttENThcfAj_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e305f57",
      "metadata": {
        "id": "2e305f57"
      },
      "outputs": [],
      "source": [
        "!dlatkInterface.py \\\n",
        "   --corpdb {database} \\\n",
        "   --corptable {msgs_table} \\\n",
        "   --correl_field user_id \\\n",
        "   --group_freq_thresh 500 \\\n",
        "   --add_ngrams -n 1 2 3 \\\n",
        "   --combine_feat_tables 1to3gram \\\n",
        "   --feat_occ_filter --set_p_occ 0.05 \\\n",
        "   --feat_colloc_filter --set_pmi_threshold 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aaf3e4e",
      "metadata": {
        "id": "4aaf3e4e"
      },
      "source": [
        "### 3.1. How many users and messages are in this dataset? How many user have more than 1,000 tokens?\n",
        "\n",
        "**HINT:** use the 1gram meta feature table...."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff715aa",
      "metadata": {
        "id": "eff715aa"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tZIoB-OX-t9k"
      },
      "id": "tZIoB-OX-t9k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "955921ef",
      "metadata": {
        "id": "955921ef"
      },
      "source": [
        "### 3.2. How many distinct feat are there in the occ 0.05 and PMI 3 1to3gram feat table?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb8433b",
      "metadata": {
        "id": "1eb8433b"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U4aM075q-z_O"
      },
      "id": "U4aM075q-z_O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7a73c205",
      "metadata": {
        "id": "7a73c205"
      },
      "source": [
        "### 3.3 How does this overall number of 1to3grams relate to the rules of thumbs we've mentioned?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2050d35",
      "metadata": {
        "id": "d2050d35"
      },
      "source": [
        "**Answer**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XCBW4Tq2-1qT"
      },
      "id": "XCBW4Tq2-1qT"
    },
    {
      "cell_type": "markdown",
      "id": "67ce8367",
      "metadata": {
        "id": "67ce8367"
      },
      "source": [
        "## 4) (2 pts + 2 extra) Full blog-authorship dataset: language correlations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1) Correlate 1to3grams with bonferroni correction and group_freq_thresh (GFT = 1000) for gender, age, occupation and star sign.\n",
        "\n",
        "Before you set up your DLATK command, have a look at `gender` in the outcomes table, in case any variable formatting has changed from what you've seen before in a way that you need to consider (describe in SQL, etc).\n",
        "\n",
        "**Tip:** P-corrections can be adjusted with `--p_correction`  \n",
        "\n",
        "🚨 **FYI:** This will take ~1.5 hours! Consider starting with just a few outcomes, like gender and age, so you can debug as needed.\n",
        "\n",
        "**Pro-tip:** Pipe away the DLATK output."
      ],
      "metadata": {
        "id": "4g9ugRi6NnvD"
      },
      "id": "4g9ugRi6NnvD"
    },
    {
      "cell_type": "markdown",
      "id": "40e479d7",
      "metadata": {
        "id": "40e479d7"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Gr8B8D8-4_B"
      },
      "id": "0Gr8B8D8-4_B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "daaf78ac",
      "metadata": {
        "id": "daaf78ac"
      },
      "source": [
        "### 4.2) Please make LIWC2015 word clouds with bonferroni correction and GFT = 1000 for age, gender, occupation and star sign.\n",
        "\n",
        "By LIWC2015 word clouds, we mean word clouds that contain the name of the LIWC dictionaries themselves as features.\n",
        "\n",
        "Note that you will need to extract the `LIWC2015` feature table (`feat$cat_LIWC2015$msgs$user_id$1gra`) first. And then run the correlations (which will be much quicker, 2-3 minutes).\n",
        "\n",
        "**Tip:** Check the \"setup\" section and section 7 of *Tutorial 09* for LIWC extraction and LIWC word clouds.\n",
        "\n",
        "**Pro-tip:** pipe away the DLATK output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'blog_authorship'\n",
        "msgs_table = 'blog_authorship_msgs'"
      ],
      "metadata": {
        "id": "Ngz1BHyRyDdT"
      },
      "id": "Ngz1BHyRyDdT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dlatkInterface.py \\\n",
        "    --corpdb {database} \\\n",
        "    --corptable {msgs_table} \\\n",
        "    --correl_field user_id \\\n",
        "    --group_freq_thresh 0 \\\n",
        "    --add_lex_table -l LIWC2015"
      ],
      "metadata": {
        "id": "BsRJLb52xw5v"
      },
      "id": "BsRJLb52xw5v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "faaf45ca",
      "metadata": {
        "id": "faaf45ca"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yuqqZCES_B98"
      },
      "id": "yuqqZCES_B98",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e8074ed3",
      "metadata": {
        "id": "e8074ed3"
      },
      "source": [
        "### 4.3) EXTRA CREDIT (2pts) For an occupation of your choice, please create a \"language summary figure.\"\n",
        "\n",
        "One nice thing about showing LIWC correlations next to 1to3gram corelations is that the LIWC cloud summarizes the 1to3gram word cloud.\n",
        "\n",
        "Using the [PPT template](https://comppsychology.github.io/psych290/wordcloud_template.pptx), in one figure, please arrange\n",
        "* The positively correlated 1to3gram word cloud for your chosen occupation.\n",
        "* Next to it, the positively correlated LIWC2015 dictionaries for the same occupation.\n",
        "* Add labels stating the name of the occupations shown, and the range of association coefficients (see word cloud file names).\n",
        "* Please also add the legend that explains size and color (see template).\n",
        "\n",
        "Please insert a screenshot of your figure."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0bdcabf",
      "metadata": {
        "id": "a0bdcabf"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_shGj1j6_DfT"
      },
      "id": "_shGj1j6_DfT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c2b292bc",
      "metadata": {
        "id": "c2b292bc"
      },
      "source": [
        "### 4.4) Please comment on the star sign word clouds in this large blog_authorship corpus in relationship to the star sign word clouds derived from the N ~ 1,000 dataset you've seen in this tutorial. What's your best estimate about  astrology carrying psychological signal?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa5d5235",
      "metadata": {
        "id": "fa5d5235"
      },
      "source": [
        "**Answer**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uysT0xoM_E2h"
      },
      "id": "uysT0xoM_E2h"
    },
    {
      "cell_type": "markdown",
      "id": "6f110002",
      "metadata": {
        "id": "6f110002"
      },
      "source": [
        "## 5) (5 points) Annotated Emotion dataset\n",
        "For these questions, we will be using a dataset made available by [Svitlana Volkova](https://www.pnnl.gov/people/svitlana-volkova). It contains ~29k Tweets annotated with emotions.\n",
        "\n",
        "We will make a new database called `svitlana`. Here, the documents (=tweets) are directly annotated with one of a few emotions. To make life easier for you, we will add an `outcomes` table, that has the emotions listed for a given `message_id`. z\n",
        "\n",
        "📝\n",
        "Note that in real life when you get a csv that has two columns: tweet and emotion. You would have to import that data into R following Tutorial 7, and create a message table with the columns `message` (the tweet) and `message_id` (some number you pick), that connect to an outcome table that has columns `message_id` and `emotion` as an outcome. For simplicity, we've done that for you.\n",
        "\n",
        "Citation for the dataset -\n",
        "```\n",
        "Volkova, S., & Bachrach, Y. (2016, August). Inferring perceived demographics from user emotional tone and user-environment emotional contrast. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 1567-1578).\n",
        "```\n",
        "\n",
        "💡 Let's start by importing the preprocessed CSVs to a SQLite database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2e0470b",
      "metadata": {
        "id": "c2e0470b"
      },
      "outputs": [],
      "source": [
        "# name of new database\n",
        "database = 'svitlana'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dlatk.tools.importmethods import csvToSQLite\n",
        "\n",
        "# point to the database file path\n",
        "database_path = os.path.join(\"sqlite_data\", database)\n",
        "\n",
        "# insert the messages CSV into the new database\n",
        "csvToSQLite(\"./psych290_data/svitlana/svitlana_msgs.csv\", database_path, \"svitlana_msgs\")\n",
        "\n",
        "# insert the outcomes CSV into the new database\n",
        "csvToSQLite(\"./psych290_data/svitlana/svitlana_outcomes.csv\", database_path, \"svitlana_outcomes\")"
      ],
      "metadata": {
        "id": "dTNnhZpeaMvs"
      },
      "id": "dTNnhZpeaMvs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the usual SQLite database connection procedure!"
      ],
      "metadata": {
        "id": "G6JH6zUM8joV"
      },
      "id": "G6JH6zUM8joV"
    },
    {
      "cell_type": "code",
      "source": [
        "# reloads the %%sql extension\n",
        "%reload_ext sql\n",
        "\n",
        "# connects the extension to the database - mounts the database as an engine\n",
        "from sqlalchemy import create_engine\n",
        "svitlana_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "\n",
        "# use engine (activates the connection to new database!!)\n",
        "%sql svitlana_engine\n",
        "\n",
        "#set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50"
      ],
      "metadata": {
        "id": "V5RhAumfXAVp"
      },
      "id": "V5RhAumfXAVp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "81f7a761",
      "metadata": {
        "id": "81f7a761"
      },
      "source": [
        "### 5.1) How many messages are there? How many messages are there per emotion?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01cee650",
      "metadata": {
        "id": "01cee650"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GXhUjQg0_H_i"
      },
      "id": "GXhUjQg0_H_i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9479b74e",
      "metadata": {
        "id": "9479b74e"
      },
      "source": [
        "### 5.2) Please extract 1grams. How many 1grams are there unfiltered? is that too many for 1gram wordclouds given our rules of thumb? Also, to orient ourselves: what's the average length of a message (tweet)?\n",
        "\n",
        "This will take ~13min. Note that the `--correl_field` will have to be `message_id`.\n",
        "\n",
        "**HINT:** remember that meta tables exist.\n",
        "\n",
        "**Note:** no GFT setting is needed on raw 1gram extraction, but you could set it anyway so as not to forget what's appropriate here (i.e., setting GFT such that everything is included)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6814968",
      "metadata": {
        "id": "c6814968"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ywNKBsUy_Lve"
      },
      "id": "ywNKBsUy_Lve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "39a7ad90",
      "metadata": {
        "id": "39a7ad90"
      },
      "source": [
        "### 5.3) Tuning message-level occurrence thresholds\n",
        "\n",
        "We want to create 1gram word clouds for the different emotions.\n",
        "\n",
        "Previously, for the choice of occurence threshold we've used user-level rules of thumb (such as 5% of all groups). Now that we are at the message level, an occurrence threshold of 5% would mean that the word would have to be contained in 5% of all messages -- that turns out to only be true of the 47 most frequent 1grams, given that Tweets are ~15 words long.\n",
        "\n",
        "So please, pick an occurrence threshold that makes sense for this situation. In this dataset with  30,000 documents, let's aim for a feature to be included if it appears in ~30 messages -- so enough for us to correlate over, barely. Can you pick an occurrence threshold that satisfies that condition? How many features are left at that threshold?\n",
        "\n",
        "⚠️ Careful to pick a GFT that's appropriate for very short messages/groups -- to include all tweets. I.e., `0`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02a321fd",
      "metadata": {
        "id": "02a321fd"
      },
      "source": [
        "**Answer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-J7Yp7zo_Wq9"
      },
      "id": "-J7Yp7zo_Wq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8a30f7fd",
      "metadata": {
        "id": "8a30f7fd"
      },
      "source": [
        "### 5.4) 1gram word clouds for emotions\n",
        "\n",
        "Please make 1gram word clouds for message level emotion annotations -- i.e., word clouds that show the words most (positively) correlated with the different emotions.\n",
        "\n",
        "Insert screenshots for two emotions of your choice. (you insert images from Edit > Insert Image).\n",
        "\n",
        "**Pro-tip:** Pipe the DLATK output `> logs.txt 2>&1` away to suppress oppressive output.\n",
        "\n",
        "Expected DLATK runtime: 3 minutes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c277b308",
      "metadata": {
        "id": "c277b308"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdSbZ_Zp_bM6"
      },
      "id": "jdSbZ_Zp_bM6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "07cf96a1",
      "metadata": {
        "id": "07cf96a1"
      },
      "source": [
        "### 5.5) LIWC word clouds for emotions\n",
        "\n",
        "Please create \"LIWC wordclouds\" for the emotion annotations, and insert screenshots for the same two emotions you picked above.\n",
        "\n",
        "This will allow us to look at the emotion annotations through a 1gram lens, and through a LIWC lens.\n",
        "\n",
        "Commands should run fast."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb34dd1",
      "metadata": {
        "id": "2eb34dd1"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qiY7UAzJ_e8m"
      },
      "id": "qiY7UAzJ_e8m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‼️ **Save your database** ‼️"
      ],
      "metadata": {
        "id": "bS4qTq9zJdUS"
      },
      "id": "bS4qTq9zJdUS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save all this work into database files in your GDrive `sqlite_databases` folder!"
      ],
      "metadata": {
        "id": "qGExUsbZThmO"
      },
      "id": "qGExUsbZThmO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First, `dla_tutorial.db`**"
      ],
      "metadata": {
        "id": "F7RlPan-KkYX"
      },
      "id": "F7RlPan-KkYX"
    },
    {
      "cell_type": "code",
      "source": [
        "dla_database = 'dla_tutorial'\n",
        "\n",
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# copy the database file to your Drive\n",
        "!cp -f \"sqlite_data/{dla_database}.db\" \"/content/drive/MyDrive/sqlite_databases/\""
      ],
      "metadata": {
        "id": "Ls5d7ZXwJzxV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Ls5d7ZXwJzxV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Second, `blog_authorship.db`** (this may take ~1 min because of it's size)"
      ],
      "metadata": {
        "id": "WxSmE9X4OByF"
      },
      "id": "WxSmE9X4OByF"
    },
    {
      "cell_type": "code",
      "source": [
        "blog_authorship = 'blog_authorship'\n",
        "\n",
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# copy the database file to your Drive\n",
        "!cp -f \"sqlite_data/{blog_authorship}.db\" \"/content/drive/MyDrive/sqlite_databases/\""
      ],
      "metadata": {
        "id": "W13oC1u3NyRE"
      },
      "id": "W13oC1u3NyRE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Third, `svitlana.db`**"
      ],
      "metadata": {
        "id": "wA-W2_suOIse"
      },
      "id": "wA-W2_suOIse"
    },
    {
      "cell_type": "code",
      "source": [
        "svitlana_database = 'svitlana'\n",
        "\n",
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# copy the database file to your Drive\n",
        "!cp -f \"sqlite_data/{svitlana_database}.db\" \"/content/drive/MyDrive/sqlite_databases/\""
      ],
      "metadata": {
        "id": "bu3Ce40TN32i"
      },
      "id": "bu3Ce40TN32i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We generated a lot of output in this tutorial! Here's how you can save it to your Drive if you want to!"
      ],
      "metadata": {
        "id": "_R0h2jyyJfah"
      },
      "id": "_R0h2jyyJfah"
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = './output_hw6'"
      ],
      "metadata": {
        "id": "pZl5sNn-J655"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pZl5sNn-J655"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Copy the database file to your Drive (-r makes it copy the folder and all files/folders inside)\n",
        "!cp -f -r {OUTPUT_FOLDER} \"/content/drive/MyDrive/\"\n",
        "\n",
        "print(f\"✅ '{OUTPUT_FOLDER}' has been copied to your Google Drive.\")"
      ],
      "metadata": {
        "id": "bwD74MqNJzR-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bwD74MqNJzR-"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}