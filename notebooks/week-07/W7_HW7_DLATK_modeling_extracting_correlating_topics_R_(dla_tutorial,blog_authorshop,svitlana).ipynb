{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CompPsychology/psych290_colab_public/blob/main/notebooks/week-07/W7_HW7_DLATK_modeling_extracting_correlating_topics_R_(dla_tutorial%2Cblog_authorshop%2Csvitlana).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7297c1b9",
      "metadata": {
        "id": "7297c1b9"
      },
      "source": [
        "# W7 Homework 7 --  Extracting, correlating (DLATK) and plotting topics (R)\n",
        "\n",
        "(c) Johannes Eichstaedt & the World Well-Being Project, 2023.\n",
        "\n",
        "‚úãüèª‚úãüèª NOTE - You need to create a copy of this notebook before you work through it. Click on \"Save a copy in Drive\" option in the File menu, and safe it to your Google Drive.\n",
        "\n",
        "‚úâÔ∏èüêû If you find a bug/something doesn't work, please slack us a screenshot, or email johannes.courses@gmail.com.\n",
        "\n",
        "Please set up Colab first, as usual!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826a264a",
      "metadata": {
        "id": "826a264a"
      },
      "source": [
        "Every question is 1 point unless otherwise specified."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Colab with DLATK and SQLite"
      ],
      "metadata": {
        "id": "yunKG9WQJ8zB"
      },
      "id": "yunKG9WQJ8zB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install DLATK"
      ],
      "metadata": {
        "id": "zVf7Sw7zroJ5"
      },
      "id": "zVf7Sw7zroJ5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-JeYt4fVXSR"
      },
      "outputs": [],
      "source": [
        "# installing DLATK and necessary packages\n",
        "!git clone -b psych290 https://github.com/dlatk/dlatk.git\n",
        "!pip install -r dlatk/install/requirements.txt\n",
        "!pip install dlatk/\n",
        "!pip install wordcloud langid jupysql gensim==4.3"
      ],
      "id": "3-JeYt4fVXSR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the custom R script"
      ],
      "metadata": {
        "id": "40C-19itydVk"
      },
      "id": "40C-19itydVk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This github repo contains our custom R script psych290RcodeV1.R (also copies of CSVs for dla_tutorial and other tutorials)!"
      ],
      "metadata": {
        "id": "kKlcBeV9yl0_"
      },
      "id": "kKlcBeV9yl0_"
    },
    {
      "cell_type": "code",
      "source": [
        "# this downloads the csvs & script we need for this tutorial\n",
        "!git clone https://github.com/CompPsychology/psych290_data.git"
      ],
      "metadata": {
        "id": "hlvHsUuLyzE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e518d0-6f39-4dc5-c150-2df598d0d42d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'psych290_data'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 44 (delta 1), reused 1 (delta 1), pack-reused 42 (from 1)\u001b[K\n",
            "Receiving objects: 100% (44/44), 86.41 MiB | 9.14 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "Updating files: 100% (14/14), done.\n"
          ]
        }
      ],
      "id": "hlvHsUuLyzE_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° BTW, if you ever need a copy of psych290RcodeV1.R (RStudio at home!), you can download it here!"
      ],
      "metadata": {
        "id": "0G2-Q61zyb4Y"
      },
      "id": "0G2-Q61zyb4Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive and copy databases"
      ],
      "metadata": {
        "id": "ORz4GM0ArvYS"
      },
      "id": "ORz4GM0ArvYS"
    },
    {
      "cell_type": "code",
      "source": [
        "database = \"dla_tutorial\""
      ],
      "metadata": {
        "id": "hsoYPwaGdDKI"
      },
      "execution_count": 2,
      "outputs": [],
      "id": "hsoYPwaGdDKI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive & copy to Colab\n",
        "\n",
        "# connects & mounts your Google Drive to this colab space\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# this copies dlatk_lexica.db from your Google Drive to Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/dlatk_lexica.db\" \"sqlite_data\"\n",
        "\n",
        "# this copies {database}.db from your Google Drive to Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/{database}.db\" \"sqlite_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7XWXktOrzWP",
        "outputId": "ac999712-17f2-4240-f820-80a12fdfec9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "I7XWXktOrzWP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup database connection"
      ],
      "metadata": {
        "id": "oCj9VppSr5Nz"
      },
      "id": "oCj9VppSr5Nz"
    },
    {
      "cell_type": "code",
      "source": [
        "# loads the %%sql extension\n",
        "%load_ext sql\n",
        "\n",
        "# connects the extension to the database - mounts both databases as engines\n",
        "from sqlalchemy import create_engine\n",
        "tutorial_db_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "dlatk_lexica_engine = create_engine(f\"sqlite:///sqlite_data/dlatk_lexica.db?charset=utf8mb4\")\n",
        "\n",
        "# attaches the dlatk_lexica.db so tutorial_db_engine can query both databases\n",
        "from IPython import get_ipython\n",
        "from sqlalchemy import event\n",
        "\n",
        "# auto‚Äëattach the lexica db whenever tutorial_db_engine connects\n",
        "@event.listens_for(tutorial_db_engine, \"connect\")\n",
        "def _attach_lexica(dbapi_conn, connection_record):\n",
        "    dbapi_conn.execute(\"ATTACH DATABASE 'sqlite_data/dlatk_lexica.db' AS dlatk_lexica;\")\n",
        "\n",
        "%sql tutorial_db_engine\n",
        "\n",
        "#set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50"
      ],
      "metadata": {
        "id": "8q73fy-7r50h"
      },
      "execution_count": 4,
      "outputs": [],
      "id": "8q73fy-7r50h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (ONLY If nedded: SOFT RELOAD): If you have a **\"database lock\"** problem"
      ],
      "metadata": {
        "id": "zEaWoSEh7gi5"
      },
      "id": "zEaWoSEh7gi5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you face a \"database locked\" issue:\n",
        "  1. restart the session (Runtime ==> Restart Session)\n",
        "  2. run this cell to get set back up!\n",
        "\n",
        "This block is your friend! ‚ò∫Ô∏è If you are working with other databases and you get a db locked error, (1) restart the session and (2) run the cell below, changing the database variable to your database name. For example, if you're working with blog_authorship.db, do `datatbase=\"blog_authorship\"`!"
      ],
      "metadata": {
        "id": "mhYoe9Tu2x8j"
      },
      "id": "mhYoe9Tu2x8j"
    },
    {
      "cell_type": "code",
      "source": [
        "database = \"dla_tutorial\"\n",
        "\n",
        "%reload_ext sql\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "tutorial_db_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "dlatk_lexica_engine = create_engine(f\"sqlite:///sqlite_data/dlatk_lexica.db?charset=utf8mb4\")\n",
        "\n",
        "# set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50\n",
        "\n",
        "from IPython import get_ipython\n",
        "from sqlalchemy import event\n",
        "\n",
        "# auto‚Äëattach the lexica db whenever tutorial_db_engine connects\n",
        "@event.listens_for(tutorial_db_engine, \"connect\")\n",
        "def _attach_lexica(dbapi_conn, connection_record):\n",
        "    dbapi_conn.execute(\"ATTACH DATABASE 'sqlite_data/dlatk_lexica.db' AS dlatk_lexica;\")\n",
        "\n",
        "%sql tutorial_db_engine"
      ],
      "metadata": {
        "id": "fvWfMDXB7gEr"
      },
      "execution_count": 1,
      "outputs": [],
      "id": "fvWfMDXB7gEr"
    },
    {
      "cell_type": "markdown",
      "id": "6c2d16aa",
      "metadata": {
        "id": "6c2d16aa"
      },
      "source": [
        "## 1) `dla_tutorial` database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e68935b",
      "metadata": {
        "id": "4e68935b"
      },
      "source": [
        "In the tutorials we worked with 2000 facebook topics.\n",
        "Here, you will use 500 FB topics that were modeled over a large Facebook dataset (with 14 million 2009-2011 statuses) to produce the topic tables -\n",
        "* `fb22_all_500t_cp`, and\n",
        "* `fb22_all_500t_freq`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9905779",
      "metadata": {
        "id": "f9905779"
      },
      "source": [
        "### 1.1) Extract user level **500 FB topics** using the above tables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6046ec95",
      "metadata": {
        "id": "6046ec95"
      },
      "source": [
        "#### Answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cCc-1lqErG0n"
      },
      "id": "cCc-1lqErG0n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "009e8243",
      "metadata": {
        "id": "009e8243"
      },
      "source": [
        "### 1.2) Correlate the topics against `occu`, controlling for `age` and `gender`\n",
        "\n",
        "As part of the answer to this question, do include the flags `--topic_tagcloud --make_topic_wordclouds --tagcloud_colorscheme blue` (or other colors as you prefer), to produce the wordclouds for the next question.\n",
        "\n",
        "Please don't forget to set a group_freq_thresh."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19125e70",
      "metadata": {
        "id": "19125e70"
      },
      "source": [
        "#### Answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u46Ee2JprH8D"
      },
      "id": "u46Ee2JprH8D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d107d142",
      "metadata": {
        "id": "d107d142"
      },
      "source": [
        "### 1.3) Show top 8 topics for one occupation of your choice.\n",
        "\n",
        "For this questions, feel free to use the `print_wordclouds` below that can filter for occupation. Very nice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "89f94c98",
      "metadata": {
        "id": "89f94c98"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def print_wordclouds(wordcloud_folder, occupation, num_topics):\n",
        "\n",
        "    images = glob.glob(os.path.join(wordcloud_folder, 'occu__{}'.format(occupation), '*.png'))\n",
        "    images = [image for image in images if 'beta' in image]\n",
        "    num_topics = num_topics if num_topics <= len(images) else len(images)\n",
        "\n",
        "    def get_coeff(x):\n",
        "        return float('.'.join(x.split('/')[-1].split('-')[1].split('.')[:2]))\n",
        "\n",
        "    top = sorted(images, key=lambda x: get_coeff(x))[::-1][:num_topics]\n",
        "\n",
        "    images_per_row = 4\n",
        "    fig, axes = plt.subplots(math.ceil(num_topics/images_per_row), images_per_row, figsize=(18, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for index, image in enumerate(top):\n",
        "        axes[index].set_axis_off()\n",
        "        axes[index].set_title(os.path.basename(image))\n",
        "        axes[index].imshow(mpimg.imread(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "aa91d14d",
      "metadata": {
        "id": "aa91d14d"
      },
      "outputs": [],
      "source": [
        "# WORDCLOUD_FOLDER = ''\n",
        "# OCCU = ''\n",
        "# NUM_TOPICS = 8\n",
        "\n",
        "# print_wordclouds(WORDCLOUD_FOLDER, OCCU, NUM_TOPICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a64d42",
      "metadata": {
        "id": "88a64d42"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LHW8BtqWrJB0"
      },
      "id": "LHW8BtqWrJB0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "287c70a9",
      "metadata": {
        "id": "287c70a9"
      },
      "source": [
        "## 2) R is your friend! (5 points)\n",
        "\n",
        "Using R, please plot the use of two topics over `age` in the `dla_tutorial` dataset. The literature suggests that people become more positive and other-oriented with age.\n",
        "\n",
        "First, based on nothing but your intuition as a human being alive on this earth, please pick two key words that you think indicate a prosocial and an antisocial orientation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First some R setup!"
      ],
      "metadata": {
        "id": "ljg893sbT7CG"
      },
      "id": "ljg893sbT7CG"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "e47056d0",
      "metadata": {
        "id": "e47056d0"
      },
      "outputs": [],
      "source": [
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is equivalent to install.packages() but much faster!!\n",
        "!apt-get update -qq\n",
        "!apt-get install -y r-cran-rsqlite r-cran-ggthemes r-cran-reshape2 r-cran-psych"
      ],
      "metadata": {
        "id": "8rhDgVagFtpm"
      },
      "id": "8rhDgVagFtpm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's set the database we want R to connect to (dla_tutorial!)"
      ],
      "metadata": {
        "id": "v84RaPURT0go"
      },
      "id": "v84RaPURT0go"
    },
    {
      "cell_type": "code",
      "source": [
        "database='dla_tutorial'\n",
        "\n",
        "# constructs the pathname\n",
        "database_path = f\"sqlite_data/{database}.db\"\n",
        "database_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3b4kqv36Rv90",
        "outputId": "8dc2e807-a19d-494b-98f1-be1deaebc711"
      },
      "id": "3b4kqv36Rv90",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sqlite_data/dla_tutorial.db'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R  -i database_path\n",
        "\n",
        "# packages\n",
        "require(tidyverse)\n",
        "require(ggthemes)\n",
        "require(reshape2)\n",
        "require(psych)\n",
        "\n",
        "# the custom R functions we have written to work with DLATK\n",
        "source('./psych290_data/helper_files/psych290RcodeV1.R')\n",
        "\n",
        "# load DBI for generic database functions and RSQLite as the SQLite backend\n",
        "library(DBI)\n",
        "library(RSQLite)\n",
        "\n",
        "# connects to a file-based sqlite DB\n",
        "db_con <- dbConnect(RSQLite::SQLite(),\n",
        "                    dbname = database_path)\n",
        "\n",
        "# enforce UTF-8 encoding\n",
        "dbExecute(db_con, \"PRAGMA encoding = 'UTF-8';\")"
      ],
      "metadata": {
        "id": "VNZwE9hURzqy"
      },
      "id": "VNZwE9hURzqy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bd951182",
      "metadata": {
        "id": "bd951182"
      },
      "source": [
        "### 2.1) Find two topics (among the 500 FB topics) that have your two key words among the most prevalent.\n",
        "\n",
        "Using SQL, get the top 10 words from the frequency representations of those topics, and confirm that the topics represent what you had in mind. If your top keywords turn out to not work well, feel free to think of other ones.\n",
        "\n",
        "Hint: running `%sql dlatk_lexica_engine` may be handy here."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d3c18c",
      "metadata": {
        "id": "94d3c18c"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XjOaRouOrLJn"
      },
      "id": "XjOaRouOrLJn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "233b66ce",
      "metadata": {
        "id": "233b66ce"
      },
      "source": [
        "### 2.2  You have extracted 1grams above. Based on that, **shortlist the outcome table** down to users who have more than 500 words\n",
        "\n",
        "**FYI:** Refer Tutorial 07 for how to create those tables: merge meta-features onto the outcome table."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8960cba9",
      "metadata": {
        "id": "8960cba9"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-QakbwZrONV"
      },
      "id": "w-QakbwZrONV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "571c39fc",
      "metadata": {
        "id": "571c39fc"
      },
      "source": [
        "### 2.3 Using the 500-FB-topic feat table that you extracted in Q1.1, in R, `merge` the shortlisted outcome table with the subset of the topic feature table that contains your topics (from Q2.1), and **plot your topics over age.\n",
        "\n",
        "Hint: you'll need the R function `importTopicFeat()`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df77263",
      "metadata": {
        "id": "4df77263"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85VqacwCrQtL"
      },
      "id": "85VqacwCrQtL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "00f27c5f",
      "metadata": {
        "id": "00f27c5f"
      },
      "source": [
        "### 2.4) Please test if linear trends are significant (you can do that with `lm` or with a humble correlation).\n",
        "\n",
        "**Hint:** `cor.test()`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2097158",
      "metadata": {
        "id": "b2097158"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "knL9c0CVrSGI"
      },
      "id": "knL9c0CVrSGI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "06461ab0",
      "metadata": {
        "id": "06461ab0"
      },
      "source": [
        "### 2.5 Write a **half sentence** about as to whether you see support for your hypothesis. (if not, you still get full points :: science is about doing methods correctly, not about finding what you wanted. #plosOne)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb18329d",
      "metadata": {
        "id": "eb18329d"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write here:"
      ],
      "metadata": {
        "id": "cgrRC71grTI3"
      },
      "id": "cgrRC71grTI3"
    },
    {
      "cell_type": "markdown",
      "id": "7a20ae89",
      "metadata": {
        "id": "7a20ae89"
      },
      "source": [
        "## 3) Annotated Emotion dataset\n",
        "\n",
        "For these questions, we will use the Annotated Emotion dataset [Svitlana Volkova](https://www.cs.jhu.edu/~svitlana/) from Tutorial 11, which is in the `SUNET_svitlana` database. It contains ~29k Tweets annotated with emotions. Here, the documents = tweets are directly annotated with one of a few emotions. We have also added the `outcomes` table, that has the emotions listed for a given `message_id`.\n",
        "\n",
        "Citation for the dataset -\n",
        "```\n",
        "Volkova, S., & Bachrach, Y. (2016, August). Inferring perceived demographics from user emotional tone and user-environment emotional contrast. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 1567-1578).\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, set up the database connection!"
      ],
      "metadata": {
        "id": "QyiIg35XrWrx"
      },
      "id": "QyiIg35XrWrx"
    },
    {
      "cell_type": "code",
      "source": [
        "# name of database\n",
        "database = 'svitlana'"
      ],
      "metadata": {
        "id": "NUBRzVFb2ScF"
      },
      "execution_count": 86,
      "outputs": [],
      "id": "NUBRzVFb2ScF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive & copy to Colab\n",
        "\n",
        "# connects & mounts your Google Drive to this colab space\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# this copies {database}.db from your Google Drive to Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/{database}.db\" \"sqlite_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aAxLBm02dMc",
        "outputId": "604f3980-54ac-4ebc-ec47-18256b5c53af"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "6aAxLBm02dMc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The usual SQLite database connection procedure!"
      ],
      "metadata": {
        "id": "6ESmq0fY2rey"
      },
      "id": "6ESmq0fY2rey"
    },
    {
      "cell_type": "code",
      "source": [
        "# Svitlana database setup\n",
        "\n",
        "database = 'svitlana'\n",
        "\n",
        "# reloads the %%sql extension\n",
        "%reload_ext sql\n",
        "\n",
        "# connects the extension to the database - mounts the database as an engine\n",
        "from sqlalchemy import create_engine\n",
        "svitlana_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "\n",
        "# use engine (activates the connection to new database!!)\n",
        "%sql svitlana_engine\n",
        "\n",
        "# set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50"
      ],
      "metadata": {
        "id": "Tl2M_7Ns2lEH"
      },
      "execution_count": 10,
      "outputs": [],
      "id": "Tl2M_7Ns2lEH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚òùüèª **FYI**: if you face the **database locked** while using this database, Restart your session (Runtime ==> Restart session), then run the last cell again!"
      ],
      "metadata": {
        "id": "2-MGanuC20q2"
      },
      "id": "2-MGanuC20q2"
    },
    {
      "cell_type": "markdown",
      "id": "0181e542",
      "metadata": {
        "id": "0181e542"
      },
      "source": [
        "### 3.1) (2pts) First, using Tutorial 11, please model 50 topics on the Svitlana dataset.\n",
        "\n",
        "Choose an alpha of 2, and remove enough stop words so that \"him\" is not included.\n",
        "\n",
        "Note: you *may* get you a **\"database locked\"** error when you run `--estimate_lda_topics`. If that happens, (1) restart (Runtime ==> Restart session), (2) run the Svitlana database setup cells above, then (3) try your command again! üôè\n",
        "\n",
        "Hint: for looking at stopwords, extend your %sql row limit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%config SqlMagic.displaylimit = 200"
      ],
      "metadata": {
        "id": "o-8CkOGIV6_j"
      },
      "id": "o-8CkOGIV6_j",
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bd18865d",
      "metadata": {
        "id": "bd18865d"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sC1Ob66Yrc3O"
      },
      "id": "sC1Ob66Yrc3O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4e55caf2",
      "metadata": {
        "id": "4e55caf2"
      },
      "source": [
        "### 3.2) (2 pts) Please extract your 50 topics, and correlate them against emotions, **at the message level**. Show 8 topic positive correlations for an emotion of your choice.\n",
        "\n",
        "Don't forget to set your `--lexicondb` to `svitlana`, and the group_freq_thresh appropriately for short documents.\n",
        "\n",
        "Remember that the `emotion` outcome is not numerical."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35bb114a",
      "metadata": {
        "id": "35bb114a"
      },
      "source": [
        "You can use the below function to plot 8 word clouds if you point it to an emotion subfolder in the DLATK output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f1c5fd8e",
      "metadata": {
        "id": "f1c5fd8e"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def print_wordclouds(wordcloud_folder, prefix, num_topics):\n",
        "\n",
        "    image_list = glob.glob(os.path.join(wordcloud_folder, '*.png'))\n",
        "    filtered = [image for image in image_list if prefix in image]\n",
        "\n",
        "    def transform(x):\n",
        "        return float('.'.join(x.split('/')[-1].split('-')[1].split('.')[:2]))\n",
        "\n",
        "    top = sorted(filtered, key=transform)[::-1][:num_topics]\n",
        "\n",
        "    images_per_row = 4\n",
        "    fig, axes = plt.subplots(math.ceil(num_topics/images_per_row), images_per_row, figsize=(18, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for index, image in enumerate(top):\n",
        "        axes[index].set_axis_off()\n",
        "        axes[index].set_title(os.path.basename(image))\n",
        "        axes[index].imshow(mpimg.imread(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c81a91",
      "metadata": {
        "id": "42c81a91"
      },
      "outputs": [],
      "source": [
        "# WORDCLOUD_FOLDER = ''\n",
        "# PREFIX = 'pos'\n",
        "# NUM_TOPICS = 8\n",
        "\n",
        "# print_wordclouds(WORDCLOUD_FOLDER, PREFIX, NUM_TOPICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "014ffa28",
      "metadata": {
        "id": "014ffa28"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A8631J78rjrB"
      },
      "id": "A8631J78rjrB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cb99ae70",
      "metadata": {
        "id": "cb99ae70"
      },
      "source": [
        "## 4) (1pt extra credit üöÄ) `blog_authorship` database\n",
        "\n",
        "If you feel like you want extra practice extracting and correlating topics."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, set up the database connection!"
      ],
      "metadata": {
        "id": "17GM5IOabz5l"
      },
      "id": "17GM5IOabz5l"
    },
    {
      "cell_type": "code",
      "source": [
        "# define database name\n",
        "database='blog_authorship'"
      ],
      "metadata": {
        "id": "DW-nJMgrbJug"
      },
      "id": "DW-nJMgrbJug",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This may take a minute or two (it's a large database)!"
      ],
      "metadata": {
        "id": "DNoGwBYnbfpx"
      },
      "id": "DNoGwBYnbfpx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive & copy to Colab\n",
        "\n",
        "# connects & mounts your Google Drive to this colab space\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# this copies blog_authorship.db from your Google Drive to Colab\n",
        "!cp -f \"/content/drive/MyDrive/sqlite_databases/blog_authorship.db\" \"sqlite_data\""
      ],
      "metadata": {
        "id": "-2rXttpBIOzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff5e12c-3e75-4df2-8748-799c9e9de092"
      },
      "id": "-2rXttpBIOzq",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database='blog_authorship'\n",
        "\n",
        "# reloads the %%sql extension\n",
        "%reload_ext sql\n",
        "\n",
        "# connects the extension to the database - mounts the database as an engine\n",
        "from sqlalchemy import create_engine\n",
        "blog_authorship_engine = create_engine(f\"sqlite:///sqlite_data/{database}.db?charset=utf8mb4\")\n",
        "\n",
        "# use engine (this activates the connection!)\n",
        "%sql blog_authorship_engine\n",
        "\n",
        "#set the output limit to 50\n",
        "%config SqlMagic.displaylimit = 50"
      ],
      "metadata": {
        "id": "uDV84fo0bNW_"
      },
      "id": "uDV84fo0bNW_",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚òùüèª **FYI**: if you face the **database locked** while using this database, Restart your session (Runtime ==> Restart session), then run the last cell again!"
      ],
      "metadata": {
        "id": "ETSDfyoAIS8n"
      },
      "id": "ETSDfyoAIS8n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract FB topics"
      ],
      "metadata": {
        "id": "udupkXtuId13"
      },
      "id": "udupkXtuId13"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous homework, you extracted 1gram feature tables on this database (commented out below if need to run it again!).\n",
        "\n"
      ],
      "metadata": {
        "id": "h4tZJlTMb5AW"
      },
      "id": "h4tZJlTMb5AW"
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'blog_authorship'\n",
        "msgs_table = 'blog_authorship_msgs'"
      ],
      "metadata": {
        "id": "VzZgRcJ4dDH-"
      },
      "id": "VzZgRcJ4dDH-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !dlatkInterface.py \\\n",
        "#   --corpdb {database} \\\n",
        "#   --corptable {msgs_table} \\\n",
        "#   --correl_field user_id \\\n",
        "#   --group_freq_thresh 500 \\\n",
        "#   --add_ngrams -n 1"
      ],
      "metadata": {
        "id": "GQ4H-ZTXdAlj"
      },
      "id": "GQ4H-ZTXdAlj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time, you need to extract 2,000 Facebook topic features (`fb2000_cp` and `fb2000_freq_t50ll`).\n",
        "\n",
        "Below is the command to extract the topic features!"
      ],
      "metadata": {
        "id": "nR9y_pY1c_0y"
      },
      "id": "nR9y_pY1c_0y"
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'blog_authorship'\n",
        "msgs_table = 'blog_authorship_msgs'\n",
        "feat_1gram_table = 'feat$1gram$blog_authorship_msgs$user_id'\n",
        "topics_cp_table = 'fb2000_cp'"
      ],
      "metadata": {
        "id": "nC0T-C8JIdn5"
      },
      "id": "nC0T-C8JIdn5",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract. This takes ~3 min."
      ],
      "metadata": {
        "id": "F42w3fWoIhIa"
      },
      "id": "F42w3fWoIhIa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76530cf",
      "metadata": {
        "id": "a76530cf"
      },
      "outputs": [],
      "source": [
        "!dlatkInterface.py \\\n",
        "    --corpdb {database} \\\n",
        "    --corptable {msgs_table} \\\n",
        "    --correl_field user_id \\\n",
        "    --group_freq_thresh 500 \\\n",
        "    --add_lex_table -l {topics_cp_table} \\\n",
        "    --weighted_lexicon"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ad987d",
      "metadata": {
        "id": "11ad987d"
      },
      "source": [
        "### 4.1) Correlate the topics against `occu`, controlling for `age` and `gender`\n",
        "\n",
        "For an occupation of your choice, show the top 8 most correlated topics.\n",
        "\n",
        "‚è∞ This will take ~22 minutes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1a339c7",
      "metadata": {
        "id": "a1a339c7"
      },
      "source": [
        "You can use the Python function below to show the top 8 topic wordclouds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "6344d1e3",
      "metadata": {
        "id": "6344d1e3"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def print_wordclouds(wordcloud_folder, occupation, num_topics):\n",
        "\n",
        "    images = glob.glob(os.path.join(wordcloud_folder, 'occu__{}'.format(occupation), '*.png'))\n",
        "    images = [image for image in images if 'beta' in image]\n",
        "    num_topics = num_topics if num_topics <= len(images) else len(images)\n",
        "\n",
        "    def get_coeff(x):\n",
        "        return float('.'.join(x.split('/')[-1].split('-')[1].split('.')[:2]))\n",
        "\n",
        "    top = sorted(images, key=lambda x: get_coeff(x))[::-1][:num_topics]\n",
        "\n",
        "    images_per_row = 4\n",
        "    fig, axes = plt.subplots(math.ceil(num_topics/images_per_row), images_per_row, figsize=(18, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for index, image in enumerate(top):\n",
        "        axes[index].set_axis_off()\n",
        "        axes[index].set_title(os.path.basename(image))\n",
        "        axes[index].imshow(mpimg.imread(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82885d5c",
      "metadata": {
        "id": "82885d5c"
      },
      "outputs": [],
      "source": [
        "# WORDCLOUD_FOLDER = ''\n",
        "# OCCU = ''\n",
        "# NUM_TOPICS = 8\n",
        "\n",
        "# print_wordclouds(WORDCLOUD_FOLDER, OCCU, NUM_TOPICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5844ad35",
      "metadata": {
        "id": "5844ad35"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4OhqO13rnBE"
      },
      "id": "n4OhqO13rnBE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ÄºÔ∏è **Save your database and/or output files** ‚ÄºÔ∏è"
      ],
      "metadata": {
        "id": "bS4qTq9zJdUS"
      },
      "id": "bS4qTq9zJdUS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save all this work into as a new database file in your GDrive `sqlite_databases` folder!"
      ],
      "metadata": {
        "id": "qGExUsbZThmO"
      },
      "id": "qGExUsbZThmO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First **`dla_tutorial`**!"
      ],
      "metadata": {
        "id": "Usl4N9KB6e39"
      },
      "id": "Usl4N9KB6e39"
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'dla_tutorial'"
      ],
      "metadata": {
        "id": "F7RlPan-KkYX"
      },
      "execution_count": 65,
      "outputs": [],
      "id": "F7RlPan-KkYX"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# copy the database file to your Drive\n",
        "!cp -f \"sqlite_data/{database}.db\" \"/content/drive/MyDrive/sqlite_databases/\"\n",
        "\n",
        "print(f\"‚úÖ Database '{database}.db' has been copied to your Google Drive.\")"
      ],
      "metadata": {
        "id": "Ls5d7ZXwJzxV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Ls5d7ZXwJzxV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second **`svitlana`**."
      ],
      "metadata": {
        "id": "-sx-4yKX6gOb"
      },
      "id": "-sx-4yKX6gOb"
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'svitlana'"
      ],
      "metadata": {
        "id": "GRHbeF8G6sIx"
      },
      "execution_count": 67,
      "outputs": [],
      "id": "GRHbeF8G6sIx"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# copy the database file to your Drive\n",
        "!cp -f \"sqlite_data/{database}.db\" \"/content/drive/MyDrive/sqlite_databases/\"\n",
        "\n",
        "print(f\"‚úÖ Database '{database}.db' has been copied to your Google Drive.\")"
      ],
      "metadata": {
        "id": "IZN4_4uy6sIy"
      },
      "execution_count": null,
      "outputs": [],
      "id": "IZN4_4uy6sIy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third **`blog_authorship`** (if you did Q4)"
      ],
      "metadata": {
        "id": "AolXTY4KpH5p"
      },
      "id": "AolXTY4KpH5p"
    },
    {
      "cell_type": "code",
      "source": [
        "database = 'blog_authorship'"
      ],
      "metadata": {
        "id": "qOL_yQl9pH5q"
      },
      "execution_count": 69,
      "outputs": [],
      "id": "qOL_yQl9pH5q"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# copy the database file to your Drive\n",
        "!cp -f \"sqlite_data/{database}.db\" \"/content/drive/MyDrive/sqlite_databases/\"\n",
        "\n",
        "print(f\"‚úÖ Database '{database}.db' has been copied to your Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519c5f45-ef5a-42a6-ad29-588153a7f7c8",
        "id": "HGp_y1J0pH5q"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Database 'blog_authorship.db' has been copied to your Google Drive.\n"
          ]
        }
      ],
      "id": "HGp_y1J0pH5q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We generated a lot of output in this Homework! Here's how you can save it to your Drive if you want to!\n",
        "\n",
        "‚è∞ This will take a minute!"
      ],
      "metadata": {
        "id": "_R0h2jyyJfah"
      },
      "id": "_R0h2jyyJfah"
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = './output_hw7'"
      ],
      "metadata": {
        "id": "pZl5sNn-J655"
      },
      "execution_count": 71,
      "outputs": [],
      "id": "pZl5sNn-J655"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Copy the database file to your Drive (-r makes it copy the folder and all files/folders inside)\n",
        "!cp -f -r {OUTPUT_FOLDER} \"/content/drive/MyDrive/\"\n",
        "\n",
        "print(f\"‚úÖ '{OUTPUT_FOLDER}' has been copied to your Google Drive.\")"
      ],
      "metadata": {
        "id": "bwD74MqNJzR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f243768e-0e3e-4c1e-a93f-8ee388c637d9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ './output_hw7' has been copied to your Google Drive.\n"
          ]
        }
      ],
      "id": "bwD74MqNJzR-"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}